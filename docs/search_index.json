[
["index.html", "Soil Predictions using MIR-Spectroscopy 1 Introduction", " Soil Predictions using MIR-Spectroscopy Charlotte Rivard 5/8/2020 1 Introduction This guide documents the use of MIR-spectroscopy at the Woods Hole Research Center, to predict various soil health properties. It is aimed at helping other teams build soil spectral libraries, create models from their data, access model performance against known values, and ultimately make predictions on new data. The machine learning methods outlined in this document were selected after assessing the performance of a variety of models. This process is explained in the following paper: Dangal S.R.S., J. Sanderman, S. Wills, and L. Rameriz-Lopez. 2019. Accurate and Precise Prediction of Soil Properties from a Large Mid-Infrared Spectral Library. Soil Systems 3(1):11. doi:10.3390/soilsystems3010011 Questions and comments can be sent to jsanderman@whrc.org or crivard@whrc.org Woods Hole Research Center Website: whrc.org Instagram: woodsholeresearchcenter Address: 149 Woods Hole Rd, Falmouth, MA 02540 "],
["background.html", "2 Background", " 2 Background Diffuse reflectance spectroscopy (DRS) has been demonstrated to be a viable alternative for rapidly characterizing and measuring soil properties compared with time-consuming and expensive conventional soil laboratory analysis Visible (vis; 400–700 nm), near-infrared (NIR; 700–2500 nm), and mid-infrared (MIR; 2500–25,000 nm) regions have been used widely to characterize soil minerals and organic matter at the global, regional, national and local scale Vis–NIR can be preferable to MIR due to its low instrumental cost and potential for field deployment. Therefore, for soil surveys that require high sampling density with basic soil properties measurement (for, e.g., organic carbon, soil texture), vis–NIR may be preferable In contrast, the MIR region contains strong molecular vibrations of most important soil minerals and organic components As a result, models built using MIR databases often perform better compared with the vis–NIR database for many soil properties, particularly for more minor soil constituents (Soil Sciences Paper) https://www.researchgate.net/figure/Representative-soil-mid-IR-spectrum-showing-absorptions-related-to-the-mineral-and_fig1_282420764 "],
["getting-started.html", "3 Getting Started File Walkthrough Required Packages Demo Script", " 3 Getting Started The best way to get started using this code, is by downloading the Soil-Predictions-Example folder found here: Soil-Predictions-Example Folder This folder, along with all source code for this guide, can be found in the following Github Repository: whrc/Soil-Predictions-MIR File Walkthrough Within the Soil-Predictions-Example folder, you will find the following folders and files: Double click Soil-Predictions-Example.Rproj to open up the R-project. Within a project, the working directory is set to the project’s folder. Open up RUNFILE.R in the project environment. This is an example script of how to make soil predictions using spectral data. It includes the use of both PLSR models and MBL models, which are both explained in this guide. Navigate to the Functions folder. Within this folder are R files containing functions useful for MIR soil predictions. These files will be sourced by each other, and RUNFILE.R Navigate to the Data_Raw folder. This should contain: LAB_DATA.csv: A ‘.csv’ file of the lab data; At a minimum, it should have a sample_id column and the lab data for a given property SPECTRA: A folder of OPUS files containing the spectral data for each sample Required Packages Open up RUNFILE.R and install the packages listed at the top: install.packages(stringr) # processing spectra install.packages(foreach) # processing spectra install.packages(prospectr) # processing spectral set install.packages(clhs) # processing large sets {optional} install.packages(matrixStats) # preprocessing baseline transformation install.packages(plot3D) # preprocessing plotting spectral outliers {optional} install.packages(pls) # pls models install.packages(resemble) # mbl models simplerspec simplerspec documentation simplerspec is a package that streamlines the process of making models from FT-IR data. However, we were unable to install it and ended up just manually saving the functions read-opus-universal and gather-spc to the folder Functions/simplerspec stringr stringr documentation stringr is used in the processing spectra portion of the code for subsetting strings with the str_sub function foreach foreach documentation foreach is in the processing spectra portion of the code within the simplrspec function read-opus-universal prospectr prospectr documentation prospectr is used in the processing portion of the code to split it into calibration and validation sets using the function kenStone() clhs clhs documentation clhs or Conditional Latin Hypercube Sampling is used in the processing portion of the code to subset large datasets that exceed 15000 samples matrixStats matrixStats documentation matrixStats is used in the base_offset function in the preprocessing portion of the code. plot3D plot3D documentation plot3D is used within the fratio_outliers function to show spectral outliers in 3D principal component space. pls pls documentation pls is used to create partial least squares regression models. resemble resemble documentation resemble is used to create memory based learner models. Demo Script Run the RUNFILE.R script. This will create… Data_Processed: A folder containing the processed data, used to build the model and make predictions Models: A folder containing the plsr and mbl models made Predictions: A folder containing the predictions output by the script and a prediction performance log To modify for your own spectral library…. Change the spectral files in Data_Raw/SPECTRA Change the lab data in Data_Raw/LAB_DATA.csv Update the name of the property in RUNFILE.R, to match the column name of the property you would like to predict. Currently, we are predicted for “OC”. Below is the full RUNFILE.R script, organized with 3 main sections &amp; their corresponding functions, linked below and described in sections 4-7 of this guide. Data Preprocessing getSpecLib() refineSpecLib() PLSR Models makePLSModel() getModResults() getPredPLS() MBL Models runMBL() getModResults() getPredMBL() #----------------------------------------------# # Data Preprocessing # #----------------------------------------------# source(&quot;Functions/preprocess_functions.R&quot;) # Get Spectral Library Set ALL_data &lt;- getSpecLib(SAVENAME=&quot;ALL_data&quot;) # Refine Spectral Library OC_data &lt;- refineSpecLib(SPECLIB=ALL_data, PROP=&quot;OC&quot;, CALVAL=TRUE, SAVENAME=&quot;OC_data&quot;) # Define Reference and Prediction Sets refSet &lt;- OC_data[OC_data$calib==1,] predSet &lt;- OC_data[OC_data$calib==0,] #----------------------------------------------# # Partial Least Squares Regression # #----------------------------------------------# source(&quot;Functions/plsr_functions.R&quot;) source(&quot;Functions/perform_functions.R&quot;) # Make Model plsr.OC &lt;- makePLSModel(PROP=&quot;OC&quot;, REFNAME=&quot;refSet&quot;) # Make Predictions pls.predictions &lt;- getModResults(PROP=&quot;OC&quot;, MODTYPE=&quot;PLS&quot;, MODNAME= &quot;plsr.OC&quot;, PREDNAME= &quot;predSet&quot;) #----------------------------------------------# # Memory Based Learner Model # #----------------------------------------------# source(&quot;Functions/mbl_functions.R&quot;) source(&quot;Functions/perform_functions.R&quot;) # Make Model mbl.OC &lt;- runMBL(PROP=&quot;OC&quot;, REFNAME=&quot;refSet&quot;, PREDNAME=&quot;predSet&quot;) # Extract Predictions mbl.predictions &lt;- getModResults(PROP=&quot;OC&quot;, MODTYPE=&quot;MBL&quot;, MODNAME= &quot;mbl.OC&quot;, PREDNAME= &quot;predSet&quot;) "],
["data-preprocessing.html", "4 Data Preprocessing Get Spectral Library Refine Spectral Library", " 4 Data Preprocessing This section of the demo script preprocesses the spectral and lab data that will be used to make models and predictions from. The following subsections explain the steps of preprocessing and their respective functions in more detail #----------------------------------------------# # Data Preprocessing # #----------------------------------------------# source(&quot;Functions/preprocess_functions.R&quot;) # Get Spectral Library Set ALL_data &lt;- getSpecLib(SAVENAME=&quot;ALL_data&quot;) # Refine Spectral Library OC_data &lt;- refineSpecLib(SPECLIB=ALL_data, PROP=&quot;OC&quot;, CALVAL=TRUE, SAVENAME=&quot;OC_data&quot;) # Define Reference and Prediction Sets #load(&quot;Data_Processed/OC_data.RData&quot;) refSet &lt;- OC_data[OC_data$calib==1,] predSet &lt;- OC_data[OC_data$calib==0,] Data Preprocessing must be performed for the reference set, used to create the models, as well as the dataset you are making predictions from, the prediction set The prediction set and reference set will be the same dataset if you are just using a single spectral library, but can be different if you are using models from one set to make predictions on another. Data preprocesing is executed by the functions within preprocess_functions.R Get Spectral Library A spectral library is simply a dataset containing spectral data for various samples. For the purpose of training models, it is also necessary to have corresponding lab data for the soil properties you are interested in predicting. getSpecLib() is a wrapper function that takes a folder of OPUS files containing spectral data, and a ‘csv’ of lab data, and outputs a merged file with all the spectral and lab data for each sample. getSpecLib() getSpecLib( SPECPATH, LABPATH, SAVENAME ) SPECPATH: string- The path to the folder of opus files, from within the ‘Soil-Predictions-Example’ folder. Default set to “/Data_Raw/SPECTRA” LABPATH: string- The path to the ‘csv’ of lab data. This file must include a sample_id column first, followed by the column(s) of lab data for the soil properties of interest. sample_id will be used to merge the spectra to its corresponding lab data SAVENAME: string- The name you would like to save the spectral file after processing. The default is set to “none” which will not save a file. getSpecLib &lt;- function(SPECPATH=&quot;/Data_Raw/SPECTRA&quot;, LABPATH=&quot;Data_Raw/LAB_DATA.csv&quot;, SAVENAME=&quot;none&quot;){ # Extract OPUS Files spectra &lt;- opus_to_dataset(SPECPATH) # Subset Spectral Range spectra$spc &lt;- subset_spectral_range(spectra$spc) # Where calibration transfer would occur # Baseline Transformation spectra$spc &lt;- base_offset(spectra$spc) # Merge with Lab Data lab &lt;- data.frame(read.csv(LABPATH)) speclib &lt;- merge(lab, spectra, all.y=TRUE) # Optional Save after Processing if(SAVENAME!= &quot;none&quot;){ assign(SAVENAME,speclib) speclib &lt;- get(SAVENAME) if(file.exists(&quot;./Data_Processed&quot;)==FALSE){dir.create(&quot;./Data_Processed&quot;)} savepath &lt;- paste0(&quot;Data_Processed/&quot;,SAVENAME,&quot;.RData&quot;) save(speclib, file=savepath) write.csv(speclib, savepath, row.names=FALSE) } return(speclib) } Output Dataset Extract Spectra For Bruker Instruments, an OPUS file containing spectral data, will be output for each sample that is scanned. To compile these separate files into one dataset, we use a couple functions from the simplerspc package by Philip Baumann, as well as the stringr and foreach packages. opus_to_dataset() opus_to_dataset( SPECPATH, NWAVE, SAVENAME ) SPECPATH: string- The path to the folder of opus files, from within the ‘Soil-Predictions-Example’ folder. Default set to “/Data_Raw/SPECTRA” NWAVE: integer- The number of wavelengths to extract. This will be set on the FTIR before running. The default is set to 3017, which we use at WHRC SAVENAME: string- The name you would like to save the spectral file after processing. The default is set to “none” which will not save a file. _ Load appropriate packages for opus_to_dataset()… #---Packages---# library(stringr) #used for str_sub library(foreach) #used within read-opus-universal.R source(&quot;Functions/gather-spc.R&quot;) #simplerspec function source(&quot;Functions/read-opus-universal.R&quot;) #simplerspec function Get the paths of all OPUS files… #---List Files---# spectraPath &lt;- &quot;/Data_Raw/ref-SPECTRA&quot; #folder of OPUS files dirs &lt;- list.dirs(paste(getwd(),spectraPath,sep=&quot;&quot;), full.names=TRUE) all.files &lt;- list.files(dirs, pattern= &quot;*.0&quot;, recursive=TRUE,full.names=TRUE) A single path will look something like this: /Soil-Predictions-Example/Data_Raw/ref-SPECTRA/WHRC03405_S_001_030.0 Extract the spectra and gathers it into a tibble data frame… #---Extract Spectra---# spc_list &lt;- read_opus_univ(fnames = all.files, extract = c(&quot;spc&quot;)) soilspec_tbl &lt;- spc_list %&gt;% gather_spc() spc &lt;- soilspec_tbl$spc Truncate the dataset to the number of wavelengths specified, to ensure the spectra from different samples align… #---Truncate Spectra---# spc.trun &lt;- lapply(1:length(spc),function(x) spc[[x]][,1:NWAVE]) # Truncate at 3017 by default Process spectra into a dataframe and #---Process to Dataframe---# spc.df &lt;- as.data.frame(matrix(unlist(spc), nrow=length(spc), byrow=T)) colnames(spc.df) &lt;- colnames(spc[[1]]) rownames(spc.df) &lt;- as.character(seq(1,nrow(spc.df))) Assign a sample_id based off the file names1… #---Assign sample_ids---# spc.df &lt;- data.frame(sample_id = soilspec_tbl$sample_id, spc.df) spc.df$sample_id &lt;- str_sub(spc.df$sample_id,1,9) Reformat the dataframe to have all the spectra as a matrix column… #---Reformat w/ Spectral Matrix Column---# spectra &lt;- data.frame(spc.df[,1]) spectra$spc &lt;- as.matrix(spc.df[,2:ncol(spc.df)]) colnames(spectra) &lt;- c(&quot;sample_id&quot;, &quot;spc&quot;) Optionally save the spectra as an R dataset and csv file if SAVENAME is passed… #---Optionally Saves---# if(SAVENAME != &quot;none&quot;){ assign(SAVENAME, spectra) savefile &lt;- paste0(&quot;Data_Processed/&quot;, SAVENAME, &quot;.RData&quot;) save(list= SAVENAME, file= savefile) print(SAVENAME,&quot;saved to&quot;, savefile) } Process Spectra Subset Spectral Range To yield the best predictions, we exclude areas of the spectral range that may be problematic. The following function narrows down the regions of the spectra by truncating wavenumbers below 628 and between 2268 to 2389, which is a CO2 sensitive region subset_spectral_range() subset_spectral_range( SPECTRA ) SPECTRA: matrix- A matrix of spectral data #---Edit Spectral Columns---# col.names &lt;- colnames(spectra$spc) #get column names which are wavenumbers col.names &lt;- as.numeric(substring(col.names,2)) cutoff &lt;- which(col.names &lt;= 628)[1] spectra$spc &lt;- spectra$spc[,-c(cutoff:length(col.names))] #truncate at &gt;= 628 min.index &lt;- which(col.names &lt;= 2389)[1] max.index &lt;- which(col.names &lt;= 2268)[1] spectra$spc &lt;- spectra$spc[,-c(min.index:max.index)] #remove CO2 region Baseline Transformation We can perform a baseline transformation to normalize the spectra, by subtracting the minimum values for each row/sample. base_offset() base_offset(x) x: a matrix library(matrixStats) # Used for rowMins() function base_offset &lt;- function(x){ row_mins &lt;- rowMins(x) return(x-row_mins) # Subtracts row_mins } Other Transformations Standard Normal Variate Derivatives Continuum removal Multiplicative scatter correction (Calibration Transfer) {Optional} Recommended when the spectral library of samples to be predicted was scanned by a different instrument than the samples used to built the model. For example, you would want to perform a calibration transfer on the prediction set, if you were using the KSSL library to make predictions on samples scanned at Woods Hole Research Center. Merge with Lab Data If there is lab data associated with your soil samples, this can be merged with the spectral data and later used to assess the performance of your models. The example lab dataset below provides information about where the soil sample was taken with the Site_ID and Horizon, as well as the lab measurements for various soil properties including Organic Carbon, Sand, Silt and Clay. #---Read Lab Data---# lab &lt;- data.frame(read.csv(&quot;Data_Raw/LAB_DATA.csv&quot;)) The merge() command joins the lab dataset to the spectral dataset. The all.y=TRUE parameter indicates that the final dataset will contain all the rows of spectra. This means that if some samples do not have lab data, they will be assigned a value of NA but the spectra will remain in the set. #---Merge with Spectra---# lab &lt;- data.frame(read.csv(LABPATH)) speclib &lt;- merge(lab, spectra, all.y=TRUE) Optionally save the spectra as an R dataset and csv file if SAVENAME is passed within getSpecLib()… #---Optionally Saves---# if(SAVENAME!= &quot;none&quot;){ assign(SAVENAME,speclib) speclib &lt;- get(SAVENAME) if(file.exists(&quot;./Data_Processed&quot;)==FALSE){dir.create(&quot;./Data_Processed&quot;)} savepath &lt;- paste0(&quot;Data_Processed/&quot;,SAVENAME,&quot;.RData&quot;) save(speclib, file=savepath) } The final dataframe contains a unique ID, lab data, and a matrix of spectral data called ‘spc’. It is suggested to save this file as RData so it may be reloaded as needed. Refine Spectral Library You may want to refine the samples you use to build your model or predict off of by… Subsetting the set to 15000 samples if it is large Eliminating samples with NA, negative, or outlier lab data Spliting the set or property subsets into calibration and validation groups refineSpecLib() refineSpecLib( SPECLIB, PROP, OUTLIER, LARGE, CALVAL, SAVENAME ) SPECLIB: dataframe- A dataframe object containing a sample_id column, a matrix of spectral data as column spc, and lab data columns if you intend to use the PROP parameter. PROP: string- The column name of the soil property of interest. If this is passed, the set will be refined using this lab data. Default is set to NA. OUTLIER: vector- A vector containing the outlier removal methods you would like applied to the data. Default is c(“stdev”) which detects lab data outliers. It can also be set to c(“fratio”) to detect spectral outliers, both c(“stdev”, “fratio”), or neither c(“none”) LARGE: boolean- Set to TRUE if you have a large dataset you would like to subset. Default is FALSE. CALVAL: boolean- Set to TRUE if you would like to create calibration and validation sets. It will return the dataset with a column, calib, that is assigned 1 for samples in the calibration set and 0 for those in the validation set. 80/20 split. Default is set to FALSE. SAVENAME: string- The name you would like to save the spectral file after processing. The default is set to “none” which will not save a file. # Load outlier functions source(&quot;Functions/outlier_functions.R&quot;) refineSpecLib &lt;- function(SPECLIB, PROP=NA, OUTLIER=c(&quot;stdev&quot;), LARGE=FALSE, CALVAL=FALSE, SAVENAME=&quot;none&quot;){ # Remove rows with faulty lab data if(!is.na(PROP)){ SPECLIB &lt;- noNA(SPECLIB , PROP) # Remove NAs SPECLIB &lt;- noNeg(SPECLIB , PROP) # Remove Negative if(&quot;stdev&quot; %in% OUTLIER){ SPECLIB &lt;- SPECLIB[-stdev_outliers(SPECLIB,PROP),] # Remove lab data outliers } } # Remove spectral outliers if(!(&quot;fratio&quot; %in% OUTLIER)){ #SPECLIB &lt;- SPECLIB[-fratio_outliers(SPECLIB),] # Identified with fratio } # Subset a large dataset to 15000 if(LARGE==TRUE){ SPECLIB$spc &lt;- sub_large_set(SPECLIB) # Subset to 15000 samples } # Split calibration/validation sets if(CALVAL==TRUE){ SPECLIB &lt;- calValSplit(SPECLIB) } # Save the refined reference set for OC if(SAVENAME != &quot;none&quot;){ if(file.exists(&quot;./Data_Processed&quot;)==FALSE){dir.create(&quot;./Data_Processed&quot;)} assign(SAVENAME, SPECLIB) savefile &lt;- paste0(&quot;Data_Processed/&quot;, SAVENAME, &quot;.RData&quot;) save(list= SAVENAME, file= savefile) print(SAVENAME,&quot;saved to&quot;, savefile) } return(SPECLIB) } Large Sets If you reference set exceeds 15000 samples, you may chose to subset it. We have found that 15000 is optimal for speed and performance of the models, when the reference set is very large. This subset can be performed using conditional latin hypercube sampling, with the clhs package. sub_large_set() sub_large_set( SPECLIB, SUBCOUNT) SPECLIB: dataframe- Dataframe including spectral data as a matrix ‘spc’ SUBCOUNT: integer- Number of samples to subset. Default is set to 15000 library(clhs) sub_large_set &lt;- function(SPECLIB, SUBCOUNT=15000){ spectra &lt;- data.frame(SPECLIB$spc) subset &lt;- clhs(spectra, size = SUBCOUNT, progress = TRUE, iter = 500) SPECLIB &lt;- SPECLIB[subset,] #double check return(SPECLIB) } Faulty Lab Data To yield the best models, we can exclude rows with faulty lab data (NA, negative, and outlier values). This may vary by soil property, so the process should be repeated for each property. noNA() noNA( dataset, column ) dataset: dataframe to eliminate NAs from column: column to check for NA values Gets rid of NA values… noNA &lt;- function(dataset, column){ return(dataset[!is.na(dataset[,column]),]) } noNeg() noNeg( dataset, column ) dataset: dataframe to eliminate negative values from column: column to check for negative values Gets rid of Negative values… noNeg &lt;- function(dataset, column){ return(dataset[which(dataset[,column] &gt; 0),]) } Outliers We can identify both outliers in the lab data and outliers in the spectral data, to optimize our models. The following functions are called based on the variable OUTLIER passed in refineSpecLib(). They are stored in outlier_functions.R Lab Data Outliers This outlier detection approach creates a PLS model, regresses the predictions against the lab data, and identifies the 1% of samples that were farthest from the line of best fit. These samples will be printed out in the consol and highlighted on a plot like the one below. In this case, the sample size is about 600, so 6 outliers were identified. stdev_outliers() stdev_outliers( SPECLIB, PROP, SHOW, PLOT ) SPECLIB: dataframe A dataframe to eliminate standard deviation outliers from PROP: string A column to check for standard deviation outliers SHOW: boolean Whether or not to show results. Default is TRUE. PLOT: boolean Whether or not to plot results. Default is TRUE. stdev_outliers &lt;- function(SPECLIB, PROP, SHOW=TRUE, PLOT=TRUE){ # Create a PLS model with the data pls.fit &lt;- plsr(sqrt(get(PROP))~spc, ncomp= 20, data = SPECLIB, valid=&quot;CV&quot;, segments = 50) #y, x, number components, data, cross validation, pred &lt;- c(predict(pls.fit, newdata = SPECLIB$spc,ncomp=20))^2 # Identify outliers using a standard deviation threshold sd.outlier &lt;- optimum_sd_outlier(pred, SPECLIB[,PROP], seq(0.1,3, by =0.02)) outliers &lt;- outlier_indices(pred, SPECLIB[,PROP], sd.outlier[1]) # Display outlier identification if(SHOW==TRUE){ # Show outlier prediction versus observed values predobs &lt;- data.frame(pred, SPECLIB[,PROP]) names(predobs) &lt;- c(&quot;pred&quot;, &quot;obs&quot;) print(predobs[outliers,]) # Plot with Outliers plot(pred ~ obs, data=predobs[-outliers,], main=&quot;Lab Outliers&quot;) points(pred ~ obs, data=predobs[outliers,], col=&quot;red&quot;, pch=24, bg=&quot;red&quot;) } return(outliers) } Spectral Outliers There may also be outliers in the spectral data, which we can detect and remove. Eliminating them from the reference set may build a stronger model, so this can be performed in the preprocessing stage. For the prediction set, you may want to see where the prediction samples lie within the reference set as well. Is the reference set data representative of the prediction set samples? If they fall to far outside of the reference set space, you might decide it is not appropriate to make predictions for these samples. To detect spectral outliers, we can look at the spectra in principal component space and identify which samples are farthest from the center of the data. We use a statistic called the fratio, to measure this variation. Using the scores and loadings from principal component analysis, we get predictions of the spectra, which can be compared to the actual values of the spectra. Looking at the probability distribution of the residuals with the fratio, we can flag samples that vary significantly from their predicted values. The 3D plot below shows an example of spectral outliers being detected in the principal component space of PC1, PC2 and PC3: fratio_outliers() fratio_outliers( SPECLIB, P, SHOW, PLOT ) SPECLIB: dataframe- A dataframe to eliminate standard deviation outliers from. Must include spectral matrix as ‘spc’ column. P: double- A fraction signifying the threshold to be used for detecting outliers. Default is set to 0.99 SHOW: boolean- Whether or not to show results. Default is TRUE. PLOT: boolean- Whether or not to plot results. Default is TRUE. library(plot3D) # For 3D plot fratio_outliers &lt;- function(SPECLIB, P=0.99, SHOW=TRUE, PLOT=TRUE){ # Get Principle Component Analysis pca &lt;- prcomp(SPECLIB$spc) # Get Scores scores &lt;- pca$x # Get Loadings loadings &lt;- pca$rotation # Get Predicted Spectra pred_spc &lt;- scores %*% t(loadings) # Scale Spectra spc &lt;- scale(SPECLIB$spc,scale=FALSE) # Get Residuals res &lt;- (pred_spc - spc)^2 res &lt;- sqrt(rowSums(res)) # Get Fratio for(i in 1:length(res)){ sample.fratio &lt;- (length(res)-1) * res^2/sum((res[-i])^2) } # Get Samples that Exceed the Threshold, P ok &lt;- pf(sample.fratio, 1, length(res)) outliers &lt;- which(ok&gt;P) # Display Results if(length(outliers)&gt;0){ # If there are spectral outliers if(PLOT==TRUE){ # 3D Plot x &lt;- pc1 &lt;- scores[,1] y &lt;- pc2 &lt;- scores[,2] z &lt;- pc3 &lt;- scores[,3] scatter3D(x,y,z, col=&quot;black&quot;, cex = 0.5) points3D(x[outliers], y[outliers], z[outliers], col=&quot;red&quot;, pch=16, add=TRUE) } if(SHOW==TRUE){ # Print Outliers print(&quot;Spectral Outliers&quot;) print(data.frame(sample_id=SPECLIB[outliers,1], PF=round(ok[outliers],6))) } return(outliers) }else{ print(&quot;No Spectral Outliers&quot;) } } Cal/Val Groups You may chose to subset a portion of the reference set as a calibration group which will be used to build the models- leaving the remaining samples as the validation set to test the model. Kennard Stone is a method for performing this type of separation while ensuring each group is representative of the set. The following function returns the spectral library with an additional column, ‘calib’, signifying whether or not the sample is in the calibration set. This is used in the demo script to define the reference set and prediction set: refSet &lt;- OC_data[OC_data$calib==1,] predSet &lt;- OC_data[OC_data$calib==0,] calValSplit() calValSplit( SPECLIB, FRAC ) SPECLIB: dataframe- The dataset containing a spectral matrix as column spc. FRAC: double- The fraction of data to be allocated to the calibration set. The default is 0.8 or 80%. library(prospectr) calValSplit &lt;- function(dataset){ #perform kennard stone to separate data into 80% calibration and 20% validation sets ken_stone&lt;- prospectr::kenStone(X = dataset$spc, k = as.integer(0.8*nrow(dataset)), metric = &quot;mahal&quot;, pc = 10) calib &lt;- dataset[ken_stone$model, ] valid &lt;- dataset[ken_stone$test, ] return(c(calib, valid)) } sample_ids that are numeric may cause issues while merging so a string ID is advised↩ "],
["plsr-models.html", "5 PLSR Models Model Theory Making PLSR Models Getting PLS Predictions", " 5 PLSR Models This section of the demo script creates PLSR models and gets predictions from them: #----------------------------------------------# # Partial Least Squares Regression # #----------------------------------------------# source(&quot;Functions/plsr_functions.R&quot;) source(&quot;Functions/perform_functions.R&quot;) # Make Model plsr.OC &lt;- makePLSModel(PROP=&quot;OC&quot;, REFNAME=&quot;refSet&quot;) # Make Predictions pls.predictions &lt;- getModResults(PROP=&quot;OC&quot;, MODTYPE=&quot;PLS&quot;, MODNAME= &quot;plsr.OC&quot;, PREDNAME= &quot;predSet&quot;) Model Theory Partial Least Squares Regression (PLSR) is a useful technique for making predictions on high dimensional datasets; Those with many columns or predictor variables relative to the number of rows or instances. For example, we are using 2720 columns of spectral data as predictor variables for only 478 rows of samples in the script to follow. This could cause major issues of overfitting with a simple regression and there may be a lot of redundancy in the data. PLSR models, like Principal Component Analysis (PCA), reduce the dimensionality of the dataset by creating a new set of orthogonal variables that explain the most variation in the data, called principal components. Loadings: Loadings are the weights of each of the original variables (wavenumbers) used to calculate each principal component. Represented by V in the diagram below. Scores: Scores are the location (or distance from origin) of each sample along each principal component. Represented by U in the diagram below. 2 However, instead of optimizing covariance amoung only the predictor variables, in this case the spectra, PLS optimizes covariance between the predictors and the response variable, the soil property of interest. To learn more about PLS, check out this youtube video: PLS Introductory Video Making PLSR Models The following is a wrapper function for loading the appropriate data, assigning a validation type, making a PLS model and optionally saving it. It is stored in Functions/plsr_functions.R and used directly in the demo script: source(&quot;Functions/plsr_functions.R&quot;) # Make Model plsr.OC &lt;- makePLSModel(PROP=&quot;OC&quot;, REFNAME=&quot;refSet&quot;) makePLSModel() makePLSModel( PROP, REFNAME, REFPATH, VAL_TYPE, SAVENAME ) PROP: string- The column name of soil property of interest in your reference set REFNAME: string- The name of the reference set variable, if it is already loaded into the R environment, that will be used to create the model. Use REFNAME or REFPATH REFPATH: string- The path the the RData file containing your reference set, if the reference set is not already loaded. Use REFNAME or REFPATH VALTYPE: string- {Optional} The validation method, either “LOO”, CV“, or”none“. The default is set to”CV&quot; SAVENAME: string- {Optional} The name you would like to save the spectral file after processing. The default is set to paste0(&quot;plsr.&quot;,PROP) which would save the file “plsr.OC.RData”, for example _ We use the pls package in r… #---Packages---# library(pls) If REFPATH is not NA, it will load the reference set at the path passed. Otherwise, it assumes you have passed in REFNAME, the variable name of a reference set already loaded. We use the get() command, rather than the variable itself, so that the name of the variable can be saved with our prediction performance. # Load Data if(!is.na(REFPATH)){ REFNAME &lt;- load(REFPATH) # If REFPATH is given } refset &lt;- get(REFNAME) # load as variable REFSET The plsr() command creates a model based on several inputs, outlined in the full plsr() documentation and pls manual Used in this example we have… Y The lab data/ observed data for the soil property you are trying to predict. We chose to square root transform this variable to normalize the data. Predictions made my the model are squared to back transform them. X A matrix of spectra with the same number of rows as Y ncomp The number of components that you would like to include in the model data The dataset containing Y and X valid The preferred validation type (“LOO”,“CV”,“none”) LOO for leave-one out CV for cross validation none if you chose not to include validation # Create Model model &lt;- plsr(sqrt(get(PROP))~spc, ncomp=20, data = refset , valid=VALTYPE) Optionally save the model. By default it will save to the Models folder as plsr.PROP -&gt; Ex: ‘Models/plsr.OC.RData’ # Save Model if(SAVENAME != &quot;none&quot;){ if(file.exists(&quot;./Models&quot;)==FALSE){dir.create(&quot;./Models&quot;)} # Create Folder to Save Models assign(SAVENAME, model) savefile &lt;- paste0(&quot;Models/&quot;,SAVENAME,&quot;.RData&quot;) save(list= SAVENAME, file = savefile) #Ex: plsr.OC.RData print(paste(&quot;Model saved to&quot;,savefile)) } return(model) Getting PLS Predictions The following is a function for getting PLS predictions stored in Functions/plsr_functions.R In the demo script is it called within getModResults() which is stored in Functions/perform_functions.R. pls.predictions &lt;- getModResults(PROP=&quot;OC&quot;, MODTYPE=&quot;PLS&quot;, MODNAME= &quot;plsr.OC&quot;, PREDNAME= &quot;predSet&quot;) getPredPLS() There are a few different ways of getting predictions from a pls model. Stored within the pls object itself, are the validation predictions and fitted predictions for the reference set used to build the model. However, you can also apply the model on a new dataset using the predict() function in the pls package. getPredPLS( MODEL, NCOMP, PREDTYPE, PREDSET ) MODEL: object- pls model object to get predictions from NCOMP: integer- Number of components of the model to use for getting predictions. Default is set to ncompOneSigma() PREDTYPE: string- The prediction method, “fitted” returns the predictions for the reference set, “valid” returns the validation predictions for the reference set, and “predict” will return predictions from applying the model on another dataset, PREDSET. PREDSET: dataframe- A dataframe to apply the model on to make predictions. Must have a ‘spc’ column containing a matrix of spectral data with the same number of columns as the reference set used to build the original model. _ If the prediction type is “valid”, we extract the validation predictions for the reference set, made when creating the model. These are stored within the model object at MODEL$validation$pred if(PREDTYPE==&quot;valid&quot;){ sqrt_pred &lt;- unlist(data.frame(MODEL$validation$pred)[NCOMP]) } If the prediction type is “fitted”, we extract the predictions from the reference set. These are the fitted values of the reference set to the model and are stored within the model at MODEL$fitted.values if(PREDTYPE == &quot;fitted&quot;){ sqrt_pred &lt;- unlist(data.frame(MODEL$fitted.values)[NCOMP]) } If the prediction type is “predict”, we make predictions with off of the spectra in our prediction set. if(PREDTYPE == &quot;predict&quot;){ sqrt_pred &lt;- c(predict(MODEL, newdata = PREDSET$spc, ncomp=NCOMP)) } Since we square root transformed the input lab data, we actually predicted for the square root of our property of interest. Here we square the predictions to untransform this data. predictions &lt;- c(sqrt_pred^2) names(predictions) &lt;- c(seq(1:length(predictions))) return(predictions) ncompOneSigma() This function selects the optimal number of components to use for getting pls predictions from the model. ncompOneSigma( MODEL ) MODEL: A PLS model object ncompOneSigma &lt;- function(MODEL){ ncomp &lt;- selectNcomp(MODEL, method = &quot;onesigma&quot;, plot = TRUE, ylim = c(0, 50)) return(ncomp) } The scree plot below shows how much the RMSEP decreases, with each additional component added. As you can see, the marginal improvements to the model eventually level off, and the addition of more components is not necessary for better predictions. With the method “onesigma”, the optimal number of components is selected as the first model where the RMSEP is within 1 standard error of the absolute optimal RMSEP. http://www.statistics4u.com/fundstat_eng/cc_pca_loadscore.html↩ "],
["mbl-models.html", "6 MBL Models Model Theory Running MBL Getting MBL Predictions", " 6 MBL Models This section of the demo script creates MBL models and gets predictions from them: #----------------------------------------------# # Memory Based Learner Model # #----------------------------------------------# source(&quot;Functions/mbl_functions.R&quot;) source(&quot;Functions/perform_functions.R&quot;) # Make Model mbl.OC &lt;- runMBL(PROP=&quot;OC&quot;, REFNAME=&quot;refSet&quot;, PREDNAME=&quot;predSet&quot;) # Extract Predictions mbl.predictions &lt;- getModResults(PROP=&quot;OC&quot;, MODTYPE=&quot;MBL&quot;, MODNAME= &quot;mbl.OC&quot;, PREDNAME= &quot;predSet&quot;) Model Theory Overview Memory-Based Learning (MBL) is a local modeling approach that can be used to predict a given soil property from a set of spectral data, the prediction set. Like PLS, this approach relies on a reference set, containing both spectral data and known values for the soil property of interest (ie. Organic Carbon). While PLS create a single global model which can be applied to all samples in the prediction set, MBL makes a local model for each prediction. Local models are built from a sample’s nearest neighbors: samples in the reference set that are most similar to the sample being predicted. Similarity is measured by spectral similarity, which should reflect similarities in soil composition. Since each sample has a customized model, predictions are often more accurate than PLS predictions. However, MBL models can be quite computationally intensive since 1) A model is built for each sample being predicted 2) All samples in the prediction and reference set must be related in terms of similarity Animation The animation below illustrates how local modeling works in MBL. It is shown in multidimensional space since each spectral column is a dimension of the dataset. A Shows all the samples in the prediction set (red), overlaying all the samples in the reference set (gray) B Shows a circle indicating the nearest neighbors of a sample being predicted C Shows all the samples of the prediction set with their respective nearest neighbors D Shows how local models will be created for each prediction from these nearest neighbors Resemble Powerpoint: http://www.fao.org/fileadmin/user_upload/GSP/docs/Spectroscopy_dec13/SSW2013_f.pdf Running MBL Running an MBL modeling approach is accomplished using a couple functions from the resemble package: mblControl() and mbl(). Full documentation for these functions is linked below and the following sections describe how they can be used. MBL- Resemble mbl() Documentation mbl(Yr, Xr, Yu = NULL, Xu, mblCtrl = mblControl(), dissimilarityM, group = NULL, dissUsage = &quot;predictors&quot;, k, k.diss, k.range, method, pls.c, pls.max.iter = 1, pls.tol = 1e-6, noise.v = 0.001, ...) MBL Control- Resemble mblControl() Documentation mblControl(sm = &quot;pc&quot;, pcSelection = list(&quot;opc&quot;, 40), pcMethod = &quot;svd&quot;, ws = if(sm == &quot;movcor&quot;) 41, k0, returnDiss = FALSE, center = TRUE, scaled = TRUE, valMethod = c(&quot;NNv&quot;, &quot;loc_crossval&quot;), localOptimization = TRUE, resampling = 10, p = 0.75, range.pred.lim = TRUE, progress = TRUE, cores = 1, allowParallel = TRUE) runMBL() runMBL() is a wrapper function for loading the appropriate datasets and calling the resemble functions for running an mbl model. It is used directly in the demo script as shown below: source(&quot;Functions/mbl_functions.R&quot;) mbl.OC &lt;- runMBL(PROP=&quot;OC&quot;, REFNAME=&quot;refSet&quot;, PREDNAME=&quot;predSet&quot;) runMBL() PROP: string- The column name of the soil property of interest. REFNAME: string- The name of the reference set variable, if it is already loaded into the R environment. Use REFNAME or REFPATH REFPATH: string- The path of the RData file containing your reference set, if the reference set is not already loaded. Use REFNAME or REFPATH PREDNAME: string- The name of the prediction set variable, if it is already loaded into the R environment. Use PREDNAME or PREDPATH PREDPATH: string- The path of the RData file containing your prediction set, if the prediction set is not already loaded. Use PREDNAME or PREDPATH SAVENAME: string- The name assigned to the model when it is saved. Default is set to paste0(“mbl.”,PROP) which would save “mbl.OC.RData” for example in the “Models” folder _ Load the resemble package # Run MBL Model library(resemble) Load the data If REFPATH is not NA, it will load the reference set at the path passed. Otherwise, it assumes you have passed in REFNAME, the variable name of a reference set already loaded. We use the get() command, rather than the variable itself, so that the name of the variable can be saved with our prediction performance. The same applies to the prediction set. # Load Reference Set if(!is.na(REFPATH)){ REFNAME &lt;- load(REFPATH) # If REFPATH is given } refset &lt;- get(REFNAME) # load as variable REFSET # Load Prediction Set if(!is.na(PREDPATH)){ PREDNAME &lt;- load(PREDPATH) } predSet &lt;- get(PREDNAME) Define inputs and eliminate rows with NA values # Define Input Datasets Xu &lt;- predSet$spc # Prediction Spectra Yu &lt;- sqrt(predSet[,PROP]) # Prediction Lab Data Yr &lt;- sqrt(refSet[,PROP]) # Reference Spectra Xr &lt;- refSet$spc # Reference Lab Data # Get Rid of NAs Xu &lt;- Xu[!is.na(Yu),] Xr &lt;- Xr[!is.na(Yr),] Yu &lt;- Yu[!is.na(Yu)] Yr &lt;- Yr[!is.na(Yr)] Set Control Parameters In this example, nearest neighbors will be determined in principal component space (sm='pc'), the optimal number of principal components will be used and up to 50 components will be tested (pcSelection = list('opc',50)), and nearest neighbor validation will be used (valMethod = 'NNv')- meaning for each prediction, a model will be built will all but the nearest neighbor of the sample being predicted. ctrl &lt;- mblControl(sm = &#39;pc&#39;, pcSelection = list(&#39;opc&#39;, 50), valMethod = &#39;NNv&#39;,center=TRUE,scale=FALSE,allowParallel=FALSE) Run MBL Model Option 1 - Will make local partial least squares regression models using 40, 60, 80 and 100 nearest neighbors (k= seq(40, 100, by = 20)) and using 6 components (pls.c = 6) to make predictions. Will not use the dissimilarity matrx (dissUsage = 'none'). Option 2- Will create weighted partial least squares regression models (method = &quot;wapls1&quot;) using the neighbors within 0.3, 0.4,…1 distance from the sample being predicted (k.diss = seq(0.3, 1, by=0.1)), with a minimum of 20 neighbors used (k.range = c(20, nrow(refSet))) and predicting with 3 to 20 of the components of the model (pls.c = c(minpls=3, maxpls=20)) Option 1 mbl.sqrt &lt;- mbl(Yr = Yr, Xr = Xr, Yu = Yu, Xu = Xu, mblCtrl = ctrl, dissUsage = &#39;none&#39;, k = seq(40, 100, by = 20), method = &#39;pls&#39;, pls.c = 6) Option 2 mbl.sqrt &lt;- mbl(Yr = Yr, Xr = Xr, Xu = Xu, mblCtrl = ctrl, dissUsage = &quot;none&quot;, k.diss = seq(0.3, 1, by=0.1), k.range = c(20, nrow(refSet)), pls.c = c(minpls=3, maxpls=20), method = &quot;wapls1&quot;) Save the model # Save MBL Model if(SAVENAME != &quot;none&quot;){ modelName &lt;- paste(&quot;mbl&quot;, PROP, sep=&quot;.&quot;) # Assign Object Name assign(modelName, mbl.sqrt) savefile &lt;- paste(&quot;./Models/mbl&quot;, PROP,&quot;RData&quot;, sep=&quot;.&quot;) # Save File save(list= modelName, file = savefile) cat(paste(&quot;\\nModel&quot;,modelName, &quot;saved to&quot;, savefile)) # Print Save Location } Modeling Parameters This section explains some of the main ways to customize and optimize mbl models using mbl() and mblControl() in the resemble package. Full documentation on these functions are linked below: Below is an example workflow showing the decision points of modeling with MBL. These parameters will be describe in the following subsections. Input Datasets The mbl() function accepts 4 different data products, Xu Xr Yu and Yr, summarized in the table below: Both Xs are matrices with spectral data and both Ys are vectors with lab data for the property of interest. u indicates “uncertain” for our prediction set, and r indicates “reference” for our reference set. Yu is optional, since not all prediction sets will have associated lab data. If this is the case, set Yu to NULL. See the data preprocessing tab to prepare these datasets prior to modeling. In addition, it is necessary to remove all rows in the reference set inputs (Yr and Xr) that have NA values. If you would like to include Yu but there are missing values, you must also remove those rows in both prediction set inputs (Yu and Xu). Number of columns in Xr must equal that of Xu. Number of rows in Yr must equal that of Yu, if provided. Matrix of Spectral Neighbors When selecting nearest neighbors to build a local model, the mbl() function references a spectral dissimilarity matrix, which relates samples in the prediction and reference sets. This matrix can be created by setting the sm parameter in mblControl(), or can be passed into the mbl() function as dissimilarityM if a matrix has already been made. For creating the matrix, you will have to decide how spectral dissimilarity will be calculated by setting a couple variables in mblControl(): sm can be set to a variety of different methods for measuring distance in a multidimensional space. We have used &quot;pls&quot; &quot;pc&quot; &quot;euclid&quot; &quot;cosine&quot; &quot;cor&quot; and &quot;movcor&quot; pcSelection determines how the number of principal components will be chosen for calculating Mahalonobis dissimilarity (when sm = “pc”, “loc.pc”, “pls” or “loc.pls”) We have this set to the default options of (opc,40) meaning the optimal principal component method will be used and up to 40 components will be tested. . Lastly, you can specify how the matrix will be used within the local models, if at all, by setting the dissUsage parameter to &quot;weights&quot; &quot;predictors&quot; or &quot;none&quot;. If set to &quot;predictors&quot;, the column of the matrix which shows similarity to the sample being predicted, will be added as a predictor variable to build the local model. If set to &quot;weights&quot;, the neighbors are weighted based on dissimilarity/distance (those closer to the sample being predicted receive more weight in the model). . The matrix format will look like one of the following, depending on how it will be used… A. All reference and prediction sets samples as rows and columns (“predictors”) B. Reference set samples as rows, prediction set samples as columns (“weights”) Neighbor Selection The mbl() function allows you to specify how many nearest neighbors will be used to build local models, by setting either k, or k.diss and k.range. Option 1: Set k to a sequence of numbers to test, for how many neighbors to include. seq(40, 40, by=20) , would perform 1 iteration, using 40 nearest neighbors seq(40, 100, by=20), would perform 4 iterations, using 40, 60, 80 and 100 nearest neighbors Option 2: Set a dissimilarity threshold k.diss that limits the distance to search for neighbors from a sample. You can think of it as the radius of the circles shown in the model theory animation. Set k.range to the minimum and maximum number of neighbors you want to include, within the k.diss distance. Modeling Method Once neighbors are selected, MBL builds local models using the multivariate regression method specified with the variable method in the mbl() function. pls for partial least squares regression wapls1 for weighted average pls gpr for gaussian process with dot product covariance pls.c allows you to set the number of pls components to be used if either “pls” or “wasp1” is used. A single number if pls is used A vector containing the minimum and maximum number of components to be used, if wasp1 is used Validation Method You can specify the validation method by setting the parameter valMethod within the mblControl() function. NNv for leave-nearest-neighbour-out cross validation loc_crossval for local leave group out cross validation none If you chose not to validate the model. This will improve processing speed. Getting MBL Predictions MBL predictions are stored in the mbl model as MODEL$results$model-name$pred Since you can run the MBL model with different numbers of nearest neighbors or different dissimilarity thresholds, there can be sets of predictions stored To choose the best model, we look for the model with the minimum standardized rmse, and extract predictions from this model, using the functions bestModMBL() and getPredMBL() sourced from Functions/mbl_functions.R In the demo script, getPredMBL() is called within a wrapper function, getModResults(). Complete documentation of this function can be found under the Model Performance tab mbl.predictions &lt;- getModResults(PROP=&quot;OC&quot;, MODTYPE=&quot;MBL&quot;, MODNAME= &quot;plsr.OC&quot;, PREDNAME= &quot;predSet&quot;) bestModMBL() The following function returns the model with the lowest standardized root mean standard error- an index showing how much predictions varied from observations3. bestModMBL &lt;- function(mbl.sqrt){ valType &lt;- mbl.sqrt$cntrlParam$valMethod if(valType==&quot;NNv&quot;){ index_best_model &lt;- which.min(mbl.sqrt$nnValStats$st.rmse) } if(valType==&quot;loc_crossval&quot;){ index_best_model &lt;- which.min(mbl.sqrt$localCrossValStats$st.rmse) } best_model_name &lt;- names(mbl.sqrt$results)[index_best_model] return(best_model_name) } getPredMBL() This function calls bestModMBL() to choose a model to get predictions from, unless model_name is specified otherwise. Since the lab data was square root transformed when building the model, it is back transformed (squared) after predictions are made. getPredMBL &lt;- function(mbl.sqrt, model_name=NULL){ if(is.null(model_name)){ model_name &lt;- bestModMBL(mbl.sqrt) } sqrt_preds &lt;- eval(parse( text=paste0(&quot;mbl.sqrt$results$&quot;, model_name,&quot;$pred&quot; ))) predictions &lt;- c(sqrt_preds)^2 # Reverse transform return(predictions) } getLabMBL() If lab data was input when building the model as Yu, it will be stored at MODEL$results$model-name$yu.obs. Otherwise, you will have to get it from your original prediction dataset getLabMBL &lt;- function(mbl.sqrt){ Yu &lt;- mbl.sqrt$call$Yu if(!is.null(Yu)){ sqrt_lab &lt;- eval(parse( text=paste0(&quot;mbl.sqrt$results$&quot;,best_model_name,&quot;$yu.obs&quot; ))) }else{ sqrt_lab &lt;- NULL } lab &lt;- c(sqrt_lab)^2 return(lab) } Find more about the RMSE here↩ "],
["model-performance.html", "7 Model Performance Get Results Predictions Statistics Plots", " 7 Model Performance The following section describes the function getModResults() which coordinates the steps after your pls or mbl model is created: Getting Predictions Calculating Uncertainty Generating Summary Statistics Displaying Plots This allows us to assess the performance of the model. How close are the predictions to the observed lab data? If you do not have lab data to compare your predictions to, you should simply use the functions getPredPLS() and getPredMBL() Get Results The following function returns the results for either pls or mbl models, calling upon getPredPLS() and getPredMBL() functions, then generates summary statistics and a plot of the predictions against the observations. getModResults() getModResults() PROP: string- The column name of the soil property of interest. Ex: “OC” MODTYPE: string- “MBL” or “PLS” MODNAME: string- The name of the model variable, if it is already loaded into the R environment. Use MODNAME or MODPATH MODPATH: string- The path the the RData file containing your model, if the model is not already loaded. Use MODNAME or MODPATH PREDNAME: string- The name of the prediction set variable, if it is already loaded into the R environment, that will be used to create the model. Use PREDNAME or PREDPATH PREDPATH: string- The path the the RData file containing your prediction set, if the prediction set is not already loaded. PREDNAME or PREDPATH SAVEPRED: boolean- Whether or not to save the predictions. If TRUE, predictions will be saved to the folder ‘Predictions’ using the function savePredictions(). Default is set to TRUE MODPERF: boolean- Whether or not to generate and show the prediction performance statistics. If TRUE, these statistics will be generated by the getModStats() function, and saved in the folder ‘Predictions’ in the performance log. getModResults &lt;- function(PROP, MODTYPE, MODNAME=NA, MODPATH=NA, PREDNAME=NA, PREDPATH=NA, SAVEPRED=TRUE, MODPERF=TRUE){ # Load Model if(!is.na(MODPATH)){ MODNAME &lt;- load(MODPATH) } model &lt;- get(MODNAME) # Load Prediction Set if(!is.na(PREDPATH)){ PREDNAME &lt;- load(PREDPATH) } predSet &lt;- get(PREDNAME) # Extract Predictions if(MODTYPE==&quot;MBL&quot;){ ncomp_onesigma &lt;- NA pred_type &lt;- NA predictions &lt;- getPredMBL(model) } if(MODTYPE==&quot;PLS&quot;){ # Find Optimal Number of Components ncomp_onesigma &lt;- selectNcomp(model, method = &quot;onesigma&quot;, plot=TRUE, main=PROP) # Get Predictions pred_type &lt;- &quot;predict&quot; predictions &lt;- getPredPLS(model, ncomp_onesigma, pred_type , predSet) } # Get Pred Versus Observations lab_data &lt;- predSet[,PROP] # Lab Data predobs &lt;- data.frame(predSet[,&quot;sample_id&quot;], predictions, lab_data) names(predobs) &lt;- c(&quot;sample_id&quot;,&quot;pred&quot;,&quot;obs&quot;) # {Optional} Model Performance if(MODPERF==TRUE){ modstats &lt;- getModStats(PREDOBS= predobs, PROP=PROP, NCOMP=ncomp_onesigma, MODNAME=MODNAME, PREDTYPE= pred_type, PREDNAME=PREDNAME, SAVE=TRUE) } # {Optional} Save Predictions if(SAVEPRED==TRUE){ savePredictions(predobs, PROP, MODTYPE, predSet, paste0(PREDNAME,&quot;_predictions.csv&quot;)) } names(predobs) &lt;- c(&quot;sample_id&quot;, paste0(PROP,&quot;.&quot;,MODTYPE), PROP) return(predobs) } Predictions Predictions are extracting using either getPredPLS() or getPredMBL(). These are called within getModResults() before being saved. The following functions save predictions to a file unique to each prediction set. If this file already exists, it simply adds another column of predictions. If it does not, it will create the file to save predictions in from the original prediction set. getSavePredTable() getSavePredTable &lt;- function(PREDSET, SAVENAME){ if(file.exists(&quot;./Predictions&quot;)==FALSE){dir.create(&quot;./Predictions&quot;)} predSavePath &lt;- paste0(&quot;./Predictions/&quot;, SAVENAME) if(file.exists(predSavePath) ){ all_predictions &lt;- read.csv(predSavePath) }else{ all_predictions &lt;- PREDSET[,-ncol(PREDSET)] # remove spectra, last column } return(all_predictions) } savePredictions() savePredictions &lt;- function(PREDOBS, PROP, MODTYPE, PREDSET, SAVENAME){ all_predictions &lt;- getSavePredTable(PREDSET, SAVENAME) # Make/Load file to save predictions savename &lt;- paste(PROP,MODTYPE,sep=&quot;.&quot;) # Ex: OC.PLSR column name if(!(savename %in% names(all_predictions))){ all_predictions &lt;- merge(all_predictions, PREDOBS[,1:2] , all.X=TRUE) # Merge with all_predictions ncolm &lt;- ncol(all_predictions) names(all_predictions)[ncolm] &lt;- savename savefile &lt;- paste0(&quot;Predictions/&quot;, SAVENAME) # Set file savename write.csv(all_predictions, file=savefile, row.names=FALSE) # Save cat(paste(&quot;\\nPredictions saved to&quot;, savefile)) # Print save location }else{ cat(&quot;\\nPrediction column already exists&quot;) } View(all_predictions) } Statistics After making predictions using either of the modeling methods, various summary statistics can help test the accuracy of those predictions. The u-deviation, as a measure of uncertainty, can help assess how much each prediction can be trusted. getModStats() The getModStats function returns the following statistics in a dataframe: R2 R2 adjusted Slope Y-Intercept RMSE Bias Standard deviation (of predictions) Residual prediction deviation The minimum input is the PREDOBS table containing a column ‘pred’, containing the predictions and a column ‘obs’, its corresponding lab data. The remaining parameters are characteristics about the models and prediction runs that are important to include if you are saving the statistics. getModStats &lt;- function(PREDOBS, PROP=NA, NCOMP=NA, MODNAME=NA, PREDTYPE=NA, PREDNAME=NA, SAVE=FALSE){ print(paste(PROP, &quot;Summary&quot;)) TIME &lt;- as.character(Sys.time()[1]) # Regress predicted versus observed PREDOBS &lt;- na.omit(PREDOBS) reg_mod &lt;- lm(PREDOBS$pred ~ PREDOBS$obs) sum_perf &lt;- summary(reg_mod) # Get statistics R2 &lt;- round(sum_perf$r.squared,4) R2_adj &lt;- round(sum_perf$adj.r.squared,4) b0 &lt;- round(sum_perf$coefficients[1], 2) # Y-Intercept b1 &lt;- round(sum_perf$coefficients[2],2) # Slope RMSE &lt;- round(sqrt(mean((PREDOBS$pred - PREDOBS$obs)^2)),2) bias &lt;- round((sum(PREDOBS$pred, na.rm=TRUE)- sum(PREDOBS$obs, na.rm=TRUE))/length(PREDOBS$obs),2) std &lt;- round(sd(PREDOBS$pred, na.rm=TRUE),2) # Standard Deviation rpd &lt;- round(std / RMSE,2) # Residual Prediction Deviation # Assemble Row modStats &lt;- data.frame(Timestamp=TIME, Property=PROP, Mod_Name=MODNAME, Pred_Type=PREDTYPE, Pred_Data=PREDNAME, ncomp=NCOMP, R2=R2, R2_Adj=R2_adj, Y_Int=b0, Slope=b1, RMSE=RMSE, bias=bias,STD=std, RPD=rpd) # Write Row if(SAVE==TRUE){saveModStats(modStats)} # Plot Pred Obs plot.plsr(PREDOBS$obs, PREDOBS$pred, modStats, paste(MODNAME,PREDNAME,&quot;Predictions&quot;), &quot;&quot;) # Print Statistics print(t(modStats)) return(modStats) } # End of getModStats saveModStats() The following function will save the prediction statistics and information as a row in the performance log: Predictions/prediction_performance.csv saveModStats &lt;- function(MODSTATS){ if(file.exists(&quot;./Predictions&quot;)==FALSE){dir.create(&quot;./Predictions&quot;)} modStats_file &lt;- &quot;Predictions/prediction_performance.csv&quot; if(file.exists(modStats_file)==FALSE){ write.csv(MODSTATS, file = modStats_file, row.names=FALSE) }else{ save_table &lt;- read.csv(modStats_file) save_table &lt;- rbind(save_table,MODSTATS) write.csv(save_table, modStats_file, row.names=FALSE) } print(paste(&quot;Statistics saved to&quot;, modStats_file)) } calcUDev() We can calculate uncertainty for our predictions with the u-deviation which takes into account both differences in the spectra of the prediction and reference sets, as well as the prediction performance measured against observed values. The equation for the u-deviation is shown below and explained within The Unscrambler Method References ResXValSamp: The residual variance for the prediction set spectra. See getResXValSamp(). When this is higher, the udeviation is higher. ResXValTot: The average residual variance for the reference set spectra. See getResXValTot(). When this is higher, the udeviation is lower. ResYValVar: The variance in predictions from their observed values using a cross validation method. When this is higher, the udeviation is higher. Hi: The leverage is the distance of how far samples in the prediction set are from those in the reference set. See getLeverage(). When this is higher, the udeviation is higher. Ical: The number of samples in the calibration/reference set. When this is higher, the u-deviation is lower. The following functions orchestrate these calculations: calcUDev() This function prepares the input terms of the u-deviation equation, calling the following functions in this section, and then makes the calculation. u-deviation estimates for each prediction and number of components in the model, will be returned as a matrix. To calculate the u-deviation run source(&quot;Functions/udev_functions.R&quot;) to load the appropriate functions and udeviation &lt;- calcUDev(plsr.OC, refSet, predSet, &quot;OC&quot;) with the model, reference set, prediction set and property you are working with. calcUDev &lt;- function(MODEL, REFSET, PREDSET, PROP){ x.cal.scores &lt;- MODEL$scores # Scores of reference + prediction sets x.val.scores &lt;- predict(MODEL, newdata = PREDSET$spc, type = &quot;scores&quot;) y.val.pred &lt;- predict(MODEL, newdata = PREDSET$spc) y.val.pred &lt;- y.val.pred[,1,] # Predictions loadings &lt;- MODEL$loadings # Model loadings x.val &lt;- PREDSET$spc # Spectra of prediction set obs &lt;- PREDSET[,PROP] # Lab data for prediction set ncalobj &lt;- nrow(REFSET) # Number of callibration samples # Get Leverage Hi &lt;- getLeverage(x.cal.scores, x.val.scores) # Get ResXValSamp ResXValSamp &lt;- getResXValSamp(PREDSET$spc, REFSET$spc, x.val.scores, loadings) # Get ResXValTot ResXValTot &lt;- getTotResXCal(REFSET$spc, x.cal.scores, loadings) # Get ResYValVar ResYValVar &lt;- MSEP(MODEL, intercept=FALSE)$val[1,1,] # Get U-Deviation udev &lt;- getYdev(ResYValVar, ResXValSamp, ResXValTot, Hi, ncalobj) return(udev) } getYdev() Performs the equation for the u-deviation, given input parameters. # Compute prediction error ydev getYdev &lt;- function(ResYValVar, ResXValSamp, ResXValTot, Hi.pr, ncalobj){ nobj &lt;- dim(ResXValSamp)[1] ncomp &lt;- dim(ResXValSamp)[2] ydev &lt;- matrix(0, nrow= nobj, ncol=ncomp) for( i in 1:ncomp){ ydev[,i] &lt;- sqrt(ResYValVar[i] * (ResXValSamp[,i]/ResXValTot[i] + Hi[,i] + 1/ncalobj) * (1- (i+1)/ncalobj)) } return(ydev) } getResXValSamp() Gets the residual variance for the prediction set spectra getResXValSamp &lt;- function(x.val.mat,x.cal.mat,x.val.scores,x.cal.loadings){ nobj &lt;- dim(x.val.mat)[1] # Number of samples in the prediction set ncomp &lt;- dim(x.val.scores)[2] # Number of componenets in the model npred &lt;- dim(x.cal.loadings)[1] # Number of spectral columns res.val &lt;- matrix(0, nrow=nobj, ncol=ncomp) # Empty matrix [prediction set samples X number of components] Xmeans.cal &lt;- colMeans(x.cal.mat) # Reference set means for each spectral column # Subtracting Reference set spectral means from the prediction set spectral values X.center &lt;- x.val.mat - matrix(rep(Xmeans.cal, each = nobj), nrow=nobj) # For each component in the model... for(i in 1:ncomp){ x.fac.load.wts &lt;- x.val.scores[,1:i, drop=FALSE] %*% t(x.cal.loadings[,1:i,drop=FALSE]) res.val[,i] &lt;- rowSums((-x.fac.load.wts + X.center)^2)/(npred-i) # Residual variance for prediction set spectra } return(res.val) } getTotResXCal() Gets the average residual variance for the reference/callibration set spectra. getTotResXCal &lt;- function(x.cal.mat,x.cal.scores,x.cal.loadings){ nobj &lt;- dim(x.cal.mat)[1] # Number of samples in the reference set ncomp &lt;- dim(x.cal.scores)[2] # Number of components in the model npred &lt;- dim(x.cal.loadings)[1] # Number of spectral columns res.val &lt;- matrix(0, nrow=nobj, ncol=ncomp) # Empty matrix [reference set samples X number of components] X.center &lt;- scale(x.cal.mat, scale=FALSE) # Scaled reference set spectra for(i in 1:ncomp){ x.fac.load.wts &lt;- x.cal.scores[,1:i, drop=FALSE] %*% t(x.cal.loadings[,1:i,drop=FALSE]) res.val[,i] &lt;- rowSums((-x.fac.load.wts + X.center)^2)/(npred-i) # Residual variance for refset spectra } tot.res &lt;- colMeans(res.val) # Average residual variance return(tot.res) } getLeverage() Gets the the distance of how far samples in the prediction set are from those in the reference set. getLeverage &lt;- function(scores.calib, scores.valid){ ta.calib &lt;- diag(crossprod(scores.calib)) ta.calib1 &lt;- matrix(rep(ta.calib, each = nrow(scores.valid)), nrow=nrow(scores.valid)) ncal &lt;- dim(scores.calib)[1] Hi &lt;- scores.valid^2 / ta.calib1 ncomp &lt;- dim(scores.valid)[2] nobj &lt;- dim(scores.valid)[1] Hi.pr &lt;- matrix(0, nrow=nobj, ncol=ncomp) for(i in 1:ncomp){ if(i == 1){ Hi.pr[,1] &lt;- Hi[,1] } else { Hi.pr[,i] &lt;- rowSums(Hi[,1:i]) } } Hi.pr &lt;- Hi.pr + (1/ncal) return(Hi.pr) } Plots The following function creates a scatter plot of the observed lab data against the predictions, showing the line of best fit and its equation, as well as some summary statistics. plotPred() plotPred &lt;- function(x,y, stats, name=NA, units=NA){ max &lt;- max(c(x,y)) lims = c(0,(1.1*max)) plot(y ~ x, ylab = paste(&quot;Predicted&quot;, units), xlab=paste(&quot;Observed&quot;, units), xlim = lims, ylim=lims,main = paste(name)) reg_model &lt;-lm(y~x) abline(reg_model) topstats &lt;- bquote(R^2 == .(stats$R2) * &quot;,&quot; ~~italic(bias)== .(stats$bias) * &quot;,&quot; ~~ RMSE == .(stats$RMSE)) text(min(x,y),max(x,y), topstats, pos = 4, col=&quot;blue&quot;) eqn &lt;- bquote(y== .(stats$Slope) * &quot;x&quot; * &quot; + &quot; * .(stats$Y_Int)) text(min(x,y),max(x,y)-(max(x,y)-min(x,y))/10, eqn, pos = 4, col=&quot;blue&quot;) } "],
["mbl-ensemble-approach.html", "8 MBL Ensemble Approach Model Iterations Getting started", " 8 MBL Ensemble Approach To make more robust predictions with measures of uncertainty, we use an ensemble approach with MBL. We run 20 mbl models, with different modeling parameters, so each samples has a distribution of predictions. We can then calculate the median prediction, as well as upper and lower confidence bounds. Model Iterations Model runs vary on 3 variables… How similarity is determined between samples 5 options euclid cosine cor pc pls Whether the similarity matrix is used as a predictor variable or not 2 options predictors none What modeling method is used for making local predictions 2 options pls wapls 5 x 2 x 2 = 20 model combinations Table 8.1: Model Combinations for Ensemble Approach Similarity_Metric Usage_Similarity_Matrix Local_Model euclid none wapls1 cosine none wapls1 cor none wapls1 pc none wapls1 pls none wapls1 euclid predictors wapls1 cosine predictors wapls1 cor predictors wapls1 pc predictors wapls1 pls predictors wapls1 euclid none pls cosine none pls cor none pls pc none pls pls none pls euclid predictors pls cosine predictors pls cor predictors pls pc predictors pls pls predictors pls Getting started The best way to get started using this code, is by downloading the Soil-Predictions-Ensemble-Example folder found here: Soil-Predictions-Ensemble-Example Folder This folder, along with all source code for this guide, can be found in the following Github Repository: whrc/Soil-Predictions-MIR File Walkthrough setname_prep.R Performs the calibration transfer on the spectra and saves as RData file in ‘spc’ folder Change the input csv file, the columns being selected as spectra (lines 11-12), and output name/location setname_oc.R Submit as a job through cloudops, creates all the mbl models with different parameter combinations, to output/oc folder Change input validation and calibration sets (line 32-38), property (oc) throughout the file, output location (line 107) and create output folder for soil property setname-fratio.R Calculates the fratio for all samples in the calibration and validation sets and outputs a list of outlier indices from the combined dataset. Ex: calibration set indices are 1-15000, validation set indices are from 15001-15240 Change input calibration and validation spectra (5-6 and throughout), number of directories in line 8 as needed, output location- currently ‘fratio’ subfolder. setname-extract.R Creates comprehensive files containing all predictions for each mbl model by property. (ie. pred.oc.csv, pred.bd.csv) Creates a file containing the lower, mean and upper prediction estimates for each property across all models (all-predictions.csv) Note: The calibration set spc.oc.RData, and the transfer matrix pls.moving.w2k.RData- called in the code- were both too large to be hosted in this repository "],
["references.html", "References", " References Dangal S.R.S., J. Sanderman, S. Wills, and L. Rameriz-Lopez. 2019. Accurate and Precise Prediction of Soil Properties from a Large Mid-Infrared Spectral Library. Soil Systems 3(1):11. doi:10.3390/soilsystems3010011 Vries, S. De, and Cajo J.f. Ter Braak. “Prediction Error in Partial Least Squares Regression: a Critique on the Deviation Used in The Unscrambler.” Chemometrics and Intelligent Laboratory Systems, vol. 30, no. 2, 1995, pp. 239–245., doi:10.1016/0169-7439(95)00030-5. "]
]
